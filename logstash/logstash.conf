input {
  kafka {
    bootstrap_servers => "kafka:9092"
    topics => ["ecommerce-products", "ecommerce-orders"]
    codec => json
    decorate_events => true
  }
}

filter {
  # split the batch list into individual docs
  split { field => "data" }

  # Flatten data->root so it matches your mappings
  ruby {
    code => '
      d = event.get("data")
      if d.is_a?(Hash)
        d.each { |k,v| event.set(k, v) }
      end
      event.remove("data")
    '
  }

  # If the event is a product, flatten rating fields for your mapping
  if [@metadata][kafka][topic] == "ecommerce-products" {
    ruby {
      code => '
        r = event.get("rating")
        if r.is_a?(Hash)
          event.set("rating_rate", r["rate"])
          event.set("rating_count", r["count"])
          event.remove("rating")
        end
      '
    }
  }

  # If the event is an order, compute total_items for your mapping
  if [@metadata][kafka][topic] == "ecommerce-orders" {
    ruby {
      code => '
        items = event.get("products") || []
        total = 0
        if items.is_a?(Array)
          items.each { |x| total += (x["quantity"] || 0).to_i }
        end
        event.set("total_items", total)
      '
    }
  }

  # Make Kibana time-series work using ingest_ts
  if [ingest_ts] {
    date { match => ["ingest_ts", "UNIX"] target => "@timestamp" }
  }

  mutate {
    remove_field => [
      "count",
      "type",
      "@version",
      "[event][original]",
      "event"
    ]
  }
}

output {
  if [@metadata][kafka][topic] == "ecommerce-products" {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "ecommerce-products"
    }
  } else if [@metadata][kafka][topic] == "ecommerce-orders" {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "ecommerce-orders"
    }
  }

  stdout { codec => rubydebug }
}
